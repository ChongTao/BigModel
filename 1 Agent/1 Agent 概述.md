# 一 Agent介绍

Agent能够自主感知环境、做出决策、执行动作的智能体。

![](https://alliance-communityfile-drcn.dbankcdn.com/FileServer/getFile/cmtybbs/519/984/817/2850086000519984817.20240708145348.99767649607666796440299186811095:50001231000000:2800:7926DD7BADDADF2C366F6ABC18F63F111FB666757612A743078FA87136A1BB38.png)

- **LLM（具有定义的角色和任务）**：作为代理的主要推理引擎和对话接口，负责解释用户查询，生成响应，并保持连贯性。
- **工具（向量搜索、网络搜索、API 等）**：扩展代理的能力，使其不仅限于文本生成，还能够访问外部资源、实时数据或专门的计算
- **记忆（短期和长期）**：在交互过程中捕捉上下文和相关数据。短期记忆跟踪即时对话状态，而长期记忆存储积累的知识和代理经验
- **规划（反思和自我批评）**：通过反思、查询路由或自我批评指导代理的迭代推理过程，确保有效地拆分复杂任务
- 行动：在规划下，利用记忆和工具，执行任务。

## 1.1 规划

让智能体根据目标自动制定行动计划，并按步骤调用工具、检索信息或生成内容以完成任务。

### 1.1.1 无反馈规划

无反馈规划在执行任务时**一次性生成完整计划**并执行，而不依赖执行过程中的中间反馈来调整步骤。

常见的任务分解技术包括思路链 (Chain of Thought) 和思路树 (Tree of Thoughts)，它们分别代表了单路径推理和多路径推理。

![](https://miro.medium.com/v2/resize:fit:2000/format:webp/1*A8lNI_zfrb3yUppdxW56LA.png)

适用场景：

- 流程高度标准化：批处理、ETL、固定报表、固定格式代码生成。
- 工具确定性高：纯计算、纯文本变换、离线数据充足

### 1.1.2 有反馈规划

智能体在执行任务时不断获取中间结果，根据反馈动态调整行动策略，以提高任务成功率和精度。

以 ReAct 为例，它将推理与行动结合起来，通过在思考（Thought）、行动（Action）和观察（Observation）这一系列步骤之间交替进行（重复 N 次），帮助大语言模型解决复杂任务。ReAct 通过观察形式从环境中获取反馈。

**适用场景**

- 环境不确定：网页检索、线上系统操作、多工具协同
- 任务目标明确但路径不确定：排障、数据调查、复杂代码修复
- 工具有失败概率：权限/限流/网络波动/结果不稳定

## 1.2 记忆

记录历史交互、任务状态或外部信息，使智能体能够在多轮交互或复杂任务中保持上下文连续性和决策一致性。在大语言模型智能体的研究文献中，主要区分为两种内存类型：

- **短期内存** - 涉及智能体当前状态的上下文信息，通常通过上下文内学习实现。由于上下文窗口的限制，这种内存是有时限和容量限制的。
- **长期内存** - 存储智能体过去的行为和思考，这部分信息需要在长时间内被保留并能够被回忆起来。通常通过连接至快速、可扩展的外部向量存储库来实现，以便在需要时为智能体提供相关信息。

## 1.3 工具

智能体调用的外部功能模块或 API，使其能够执行特定操作、获取数据或增强任务能力。



## 1.4 Agent和Workflow区别

- **Workflow 是规定流程（Rule-based）**
-  **Agent 是自治决策（Goal-driven）**

![](https://mmbiz.qpic.cn/sz_mmbiz_png/j3gficicyOvauNZyziaHia56WajsqXbwHetmLJB9ibxhH3sv1v13JicVPwldlCbJEfBdHsIA5NhH9iauZsgeJmGFzJzPQ/640?wx_fmt=png&from=appmsg&tp=webp&wxfrom=5&wx_lazy=1#imgIndex=1)
