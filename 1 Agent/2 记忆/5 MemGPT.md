# 一 介绍

MemGPT（Memory-GPT）是一种面向大语言模型（LLM, Large Language Model）上下文扩展与记忆管理的系统，其核心思路是：**将 LLM 当作“操作系统（OS）”来使用**，让它能够自主管理“在上下文内／上下文外”的记忆，从而突破模型固有的固定上下文窗口限制。

# 二 核心机制与架构

- **记忆层级（Memory Hierarchy）**：
  - 主上下文（main context）：类似 OS 中的“RAM”，即当前 LLM 输入提示中可直接访问的内容。
  - 外部存储／归档上下文（external/archival storage）：类似 OS 中的“磁盘”，存放那些超出当前窗口或暂时不活跃的信息。
  - 当“主上下文”快满或需要腾出空间时，系统会发出“内存压迫”警告，使 LLM 决定哪些信息可迁出、哪些重要信息需保留或提升。 
- **函数调用机制（Function Calls）**：LLM 可以通过接口调用 functions 来执行检索、记忆写入、记忆更新或删除等操作。也就是说，LLM 不只是被动接受提示，而具备“编辑自己记忆／检索外部内容”的能力。 [arXiv+1]
- **事件-控制流（Event + Interrupts）**：MemGPT 设计了“系统事件”如内存警告、用户输入、定时任务等，使 LLM 能够响应这些事件、触发记忆检索、移入或移出上下文。

![memGPT](https://miro.medium.com/v2/resize:fit:720/format:webp/0*V4z-l_8f3AHzh5a7.png)

# 三 主要应用场景

MemGPT 在两类问题场景中展现了优势：

1. **大型文档分析**：当需要分析文档远大于 LLM 上下文窗口（如法律档案、财报等）时，MemGPT 可分页检索／载入外部存储的信息，突破上下文长度限制。
2. **跨会话对话/长期记忆**：在多轮、长期交互中，MemGPT 可记住用户偏好、历史对话、实体关系等，使对话代理更具“记忆感”，而非每次重头开始。