# Agent的记忆

记忆就是让大模型能够跨越单次输入上下文，持续记住和利用信息，而不仅仅依赖于有限的上下文窗口。

## 1. 为什么需要 “记忆”

- **上下文长度有限**：即使是支持几十万 token 的长上下文模型，仍然受限于计算成本和效率。
- **持续对话 / 多轮交互**：用户希望模型能记住之前的交流，不用每次都重新说明。
- **个性化 / 长期知识**：模型需要记住用户的偏好、习惯、历史任务结果。
- **复杂任务**：像项目管理、科学研究、写书等，都需要跨会话记忆。

## 2. 记忆的常见分类

### 2.1 短期记忆（Short-term Memory）

- **定义**：类似人类的工作记忆，依赖于模型的上下文窗口（context window）。
- **特点**：随着对话长度增加，旧信息会被截断遗忘。
- **技术手段**：长上下文扩展（RoPE 插值、ALiBi、Attention Sink、滑动窗口注意力等）。
- **缺点**：成本高，不适合保存长期知识。

### 2.2 长期记忆（Long-term Memory）

- **定义**：跨会话、跨任务的记忆，能永久保存。
- **存储方式**：通常是**外部存储**（数据库、向量库、KV 存储）。
- **检索机制**：在新请求时，将历史内容做 embedding 向量化，按相似度检索，再拼接进 prompt。
- **常用技术**：
  - RAG（Retrieval-Augmented Generation）
  - 向量数据库（FAISS, Milvus, Weaviate, Pinecone 等）
  - 基于关键词 / 主题的索引
- 多模态记忆对齐

### 2.3 工作记忆（Working Memory）

- **定义**：介于短期与长期之间，类似一个临时缓存。
- **用途**：在多轮任务执行中保存中间步骤结果，供后续调用。
- **实现**：
  - 会话缓存（conversation buffer）
  - 知识图谱临时节点
  - scratchpad（推理时的草稿区，比如 Chain-of-Thought 的显式记录）

### 2.4 情节记忆（Episodic Memory）

- **定义**：存储用户与模型的“交互事件”，按会话 / 时间组织。
- **作用**：模型能回忆“上次我们聊到哪里”。
- **实现**：事件时间戳 + 向量表示 + 语义检索。

### 2.5 语义记忆（Semantic Memory）

- **定义**：将信息抽象总结为“知识点”。
- **例子**：用户常说“我喜欢用 Go 写后端” → 存成一个偏好知识条目。
- **实现**：定期对对话日志做总结 → 存到知识库。
- **优点**：节省空间，便于泛化。

### 2.6 程序化 / 工具化记忆（Tool-based Memory）

- 模型并不直接“记住”，而是通过调用外部工具访问：
  - 个人笔记系统（Notion, Obsidian）
  - 日历 / 待办事项 API
  - CRM 系统（存储用户信息）

##  3. 记忆的实现机制

1. **存储**：日志（raw text）、embedding（向量化）、结构化数据库（key-value / graph）。
2. **检索**：向量相似度、关键词匹配、混合检索。
3. **更新**：
   1. **追加式**（append-only）：记录所有内容。
   2. **总结式**（summarization）：定期归纳为简短知识。
   3. **遗忘机制**：过旧 / 不重要的记忆会被丢弃或压缩。
4. **调用**：在对话 prompt 构造时，把检索到的记忆拼接进去，让模型“读”。

### 3.1 短期记忆 

大模型的短期记忆一般指在一次会话、任务或者上下文窗口中临时保存的信息，与长期记忆不同，不会永久存储，随上下文或者缓存失效而丢失。

1. **模型本身的短期记忆**
   1. 上下文窗口
      -   大模型通过输入的token记住内容，只要内容在模型的最大上下文窗口内，模型就能利用内容回答问题，超出窗口的部分会被截断或者遗忘。
   2. 位置编码
      -   用于让模型区分输入序列中 token 的先后关系。
2. **系统实现层面的短期记忆**

在实际应用里，为了增强模型的短期记忆，可以用到以下手段：

- **缓存**：利用Redis等工具，保留一段近期的对话历史（例如滑动窗口，只保留N轮对话），作为 prompt 的一部分传给模型。
- **对话摘要**：定期将较早的对话压缩成摘要，用更少的 token 表示，节省上下文长度。

##  4. 大模型记忆研究进展

- Context Poisoning（上下文中毒）
- Context Distraction（上下文干扰）
- Context Confusion（上下文混淆）
- Context Confusion（上下文冲突）

长期记忆：

- Semantic memory：语义记忆，无论是在人类还是人工智能智能体中，都涉及对特定事实和概念的保留。
- Episodic memory：情景记忆，在人类和人工智能智能体中，都涉及回忆过去的事件或行动。
- Procedural memory：程序性记忆，无论是在人类还是人工智能智能体中，都涉及记住执行任务所使用的规则。





MemoRAG，一种基于长期记忆的检索增强生成新范式。



与传统RAG相比：

- 传统RAG：基于外部知识进行检索，没有考虑检索上下文信息。
- MemoRAG ：MemoRAG提出了一个双系统架构，采用了一个轻量级但长上下文的LLM来形成数据库的全局记忆，并在任务呈现时生成草稿答案，提示检索工具在数据库中定位有用信息。另一方面，它利用一个能力较强的LLM，根据检索到的信息生成最终答案。

MemoRAG的核心是引入了一个记忆模块，其目的是**建立数据库的全局记忆**，并生成有助于检索的线索 。两个记忆模型（memorag-qwen2-7b-inst和memoragmistral-7b-inst ）。

- 表示由记忆模型生成的中间答案，用作检索线索。
- 这个中间答案帮助检索模型从数据库中检索最相关的上下文 。

代码地址： https://github.com/qhjqhj00/MemoRAG

## 长期记忆

实现长期记忆的常见方式包括：

1. 向量数据库 + 检索（最常见）

​      采用RAG的方式，将你的历史对话和个性化信息保存下来。具体流程就是将对话信息转换为向量，存入像[FAISS](https://zhida.zhihu.com/search?content_id=259247162&content_type=Article&match_order=1&q=FAISS&zhida_source=entity)、[Milvus](https://zhida.zhihu.com/search?content_id=259247162&content_type=Article&match_order=1&q=Milvus&zhida_source=entity)等向量数据库中，当模型需要”回忆“时，就向数据库中检索相关信息，并将结果加到模型输入的prompt中。这种做法的好处是，因其基于现有的RAG系统，所以部署起来会相对简单；且由于向量数据库的加持，扩展性也会很强，最大可支持百万级的记忆内容。不过因为其没有对记忆进行分类的结构化存储，所以其在检索阶段会出现准确度低的问题，且在存储过程中可能无法理解”时间顺序“或”语境依赖“，导致记忆中忽略这部分的信息。

1. Slot-based 记忆管理（插槽式记忆）

​      向量数据库因为未采用结构化存储而导致其准确度低，那么为了解决这一问题，就需要对记忆进行结构化设计，也就是将记忆拆分为多个”插槽“。模型根据上下文选择要激活的插槽，动态组合prompt，从而生成更准确的回答。比如，大模型得到了一个user_input,内容为：“小明是重庆人，特别喜欢吃辣椒”。那么其结构化存储就可以按照如下的方式进行存储：

● 用户姓名：小明

● 喜好：爱吃辣

● 背景信息：重庆人

这样做的好处在于：记忆的储存更加结构化，方便了记忆存储与记忆召回。对于一些业务流程比较明确固定的场景，管理记忆的工作会更加方便。但是在实现过程中需要开发人员手动设定插槽，灵活性与兼容性很差。并且在插槽数量过多的时候管理起来十分复杂。

1. 多轮对话链 + 自动总结（总结记忆）

​      既然插槽式记忆需要人工设计记忆结构，那么能不能让大模型自己去完成这个工作呢？总结记忆为这一问题提出了解决方案：让模型定期“写日记”，通过总结来压缩对话历史。即在每次对话结束时，就自动总结一段记忆，或者让模型定期地对过去的对话进行“反思”，存储对话中”高度抽象“的信息，而非其原始内容。

​    比如，用户询问了一些关于旅游攻略的信息，大模型将对话总结为：”用户计划去XX旅游，关注美食以及交通信息“。这样的存储方式节省了token成本，让记忆更加紧凑，且更加接近”人类回忆“。但是因为其总结的过程时交给模型及进行处理，总结不准确会导致模型”误记“，并且总结的记忆中缺乏细节，会影响记忆召回的精确度。

1. 混合式：当前最主流的解决方案

​      a. 用向量数据库存原始记忆片段

​      b. 用slot存储结构化长期信息（如角色设定、兴趣偏好）

​      c.用总结机制压缩上下文，提高效率

OpenAI、Meta、Anthropic、Mistral 等公司在构建 Agent 系统时，几乎都采用了这种“混合记忆架构”。

- mem0：轻量、实用、以用为先的记忆系统
- MemGPT：类人脑记忆的模拟器



**Augmented Generation）** 的增强型检索生成框架，旨在让大模型不仅能“查资料”，还能“记得过去”，从而实现更持续、更上下文相关的交互与推理。

------

### 🧠 一、基本概念

传统 **RAG** 由两部分组成：

1. **Retriever（检索器）**：从外部知识库中找到与当前 query 相关的文档。
2. **Generator（生成器）**：结合检索到的内容与 query，生成最终回答。

但 **Memory RAG** 在此基础上引入了第三部分：

3. **Memory（记忆模块）**：存储与提炼模型过去的对话、交互、思考结果等，以便在后续生成中使用。



### ⚙️ 二、Memory 的作用层次

Memory 可以分为三类：

| 类型                              | 存储周期   | 内容                           | 示例                                 |
| --------------------------------- | ---------- | ------------------------------ | ------------------------------------ |
| **短期记忆（Short-term Memory）** | 一次会话内 | 当前对话历史上下文             | 聊天上下文、未完成任务状态           |
| **中期记忆（Working Memory）**    | 几轮对话间 | 当前主题相关信息               | 用户最近查询的项目、最近的上下文主题 |
| **长期记忆（Long-term Memory）**  | 持久存储   | 历史知识、个性偏好、总结性内容 | 用户兴趣、过往结论、个人配置         |

------

### 🧩 三、Memory RAG 的典型架构

```
         ┌────────────────────────────┐
         │        User Query          │
         └─────────────┬──────────────┘
                       │
             ┌─────────▼──────────┐
             │ Memory Retriever    │ ← 从记忆中检索相似上下文
             └─────────┬──────────┘
                       │
             ┌─────────▼──────────┐
             │ Knowledge Retriever │ ← 从外部知识库检索文档
             └─────────┬──────────┘
                       │
             ┌─────────▼──────────┐
             │     Fusion Model    │ ← 整合记忆与知识
             └─────────┬──────────┘
                       │
             ┌─────────▼──────────┐
             │     Generator       │ ← 输出答案
             └─────────────────────┘
```

------

### 🧩 四、关键技术

| 技术模块         | 说明                                                         |
| ---------------- | ------------------------------------------------------------ |
| **记忆向量化**   | 将对话摘要或用户行为转为向量嵌入，存入长期记忆库             |
| **记忆检索策略** | 利用语义检索（Embedding）+ 时间衰减机制 + 主题聚类 提高相关性 |
| **动态记忆更新** | 自动总结对话片段，提取持久知识，避免记忆膨胀                 |
| **融合机制**     | 生成时对来自记忆与知识的内容加权融合，控制优先级（如 Memory > Docs） |

------

### 💡 五、典型应用场景

- **智能助理**：长期记住用户偏好、历史对话、任务进度。
- **企业知识问答**：结合企业文档（RAG）与员工上下文（Memory）。
- **研究型Agent**：在长期任务中积累知识、形成自我总结。
- **教育场景**：能记住学生的学习历史、答题风格。

------

### 🧭 六、Memory RAG 的价值

| 优点                 | 说明                                 |
| -------------------- | ------------------------------------ |
| ✅ 提升上下文一致性   | 能理解用户长期意图，不再每次从零开始 |
| ✅ 降低重复检索       | 通过记忆缓存，减少重复查询外部知识库 |
| ✅ 具备“自我成长”能力 | 模型能不断积累经验与知识，越用越聪明 |

------

### 🔮 七、与其他 RAG 的区别对比

| 类型             | 核心特征               | 典型应用       |
| ---------------- | ---------------------- | -------------- |
| **Naive RAG**    | 单次检索生成，无上下文 | 问答、摘要     |
| **Advanced RAG** | 多源融合、查询优化     | 多模态问答     |
| **Modular RAG**  | 模块化组件，可定制流程 | 企业架构       |
| **Graph RAG**    | 知识图谱化检索         | 关系推理       |
| **Agentic RAG**  | 多Agent协作、自主任务  | 自动化决策     |
| **Memory RAG**   | 持续记忆、自适应学习   | 长期交互场景 ✅ |
