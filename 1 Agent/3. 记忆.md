# Agent的记忆

记忆就是让大模型能够跨越单次输入上下文，持续记住和利用信息，而不仅仅依赖于有限的上下文窗口。

## 1. 为什么需要 “记忆”

- **上下文长度有限**：即使是支持几十万 token 的长上下文模型，仍然受限于计算成本和效率。
- **持续对话 / 多轮交互**：用户希望模型能记住之前的交流，不用每次都重新说明。
- **个性化 / 长期知识**：模型需要记住用户的偏好、习惯、历史任务结果。
- **复杂任务**：像项目管理、科学研究、写书等，都需要跨会话记忆。

## 2. 记忆的常见分类

### 2.1 短期记忆（Short-term Memory）

- **定义**：类似人类的工作记忆，依赖于模型的上下文窗口（context window）。
- **特点**：随着对话长度增加，旧信息会被截断遗忘。
- **技术手段**：长上下文扩展（RoPE 插值、ALiBi、Attention Sink、滑动窗口注意力等）。
- **缺点**：成本高，不适合保存长期知识。

### 2.2 长期记忆（Long-term Memory）

- **定义**：跨会话、跨任务的记忆，能永久保存。
- **存储方式**：通常是**外部存储**（数据库、向量库、KV 存储）。
- **检索机制**：在新请求时，将历史内容做 embedding 向量化，按相似度检索，再拼接进 prompt。
- **常用技术**：
  - RAG（Retrieval-Augmented Generation）
  - 向量数据库（FAISS, Milvus, Weaviate, Pinecone 等）
  - 基于关键词 / 主题的索引
- 多模态记忆对齐

### 2.3 工作记忆（Working Memory）

- **定义**：介于短期与长期之间，类似一个临时缓存。
- **用途**：在多轮任务执行中保存中间步骤结果，供后续调用。
- **实现**：
  - 会话缓存（conversation buffer）
  - 知识图谱临时节点
  - scratchpad（推理时的草稿区，比如 Chain-of-Thought 的显式记录）

### 2.4 情节记忆（Episodic Memory）

- **定义**：存储用户与模型的“交互事件”，按会话 / 时间组织。
- **作用**：模型能回忆“上次我们聊到哪里”。
- **实现**：事件时间戳 + 向量表示 + 语义检索。

### 2.5 语义记忆（Semantic Memory）

- **定义**：将信息抽象总结为“知识点”。
- **例子**：用户常说“我喜欢用 Go 写后端” → 存成一个偏好知识条目。
- **实现**：定期对对话日志做总结 → 存到知识库。
- **优点**：节省空间，便于泛化。

### 2.6 程序化 / 工具化记忆（Tool-based Memory）

- 模型并不直接“记住”，而是通过调用外部工具访问：
  - 个人笔记系统（Notion, Obsidian）
  - 日历 / 待办事项 API
  - CRM 系统（存储用户信息）

##  3. 记忆的实现机制

1. **存储**：日志（raw text）、embedding（向量化）、结构化数据库（key-value / graph）。
2. **检索**：向量相似度、关键词匹配、混合检索。
3. **更新**：
   1. **追加式**（append-only）：记录所有内容。
   2. **总结式**（summarization）：定期归纳为简短知识。
   3. **遗忘机制**：过旧 / 不重要的记忆会被丢弃或压缩。
4. **调用**：在对话 prompt 构造时，把检索到的记忆拼接进去，让模型“读”。

### 3.1 短期记忆 

大模型的短期记忆一般指在一次会话、任务或者上下文窗口中临时保存的信息，与长期记忆不同，不会永久存储，随上下文或者缓存失效而丢失。

1. **模型本身的短期记忆**
   1. 上下文窗口
      -   大模型通过输入的token记住内容，只要内容在模型的最大上下文窗口内，模型就能利用内容回答问题，超出窗口的部分会被截断或者遗忘。
   2. 位置编码
      -   用于让模型区分输入序列中 token 的先后关系。
2. **系统实现层面的短期记忆**

在实际应用里，为了增强模型的短期记忆，可以用到以下手段：

- **缓存**：利用Redis等工具，保留一段近期的对话历史（例如滑动窗口，只保留N轮对话），作为 prompt 的一部分传给模型。
- **对话摘要**：定期将较早的对话压缩成摘要，用更少的 token 表示，节省上下文长度。

##  4. 大模型记忆研究进展

- Context Poisoning（上下文中毒）
- Context Distraction（上下文干扰）
- Context Confusion（上下文混淆）
- Context Confusion（上下文冲突）

长期记忆：

- Semantic memory：语义记忆，无论是在人类还是人工智能智能体中，都涉及对特定事实和概念的保留。
- Episodic memory：情景记忆，在人类和人工智能智能体中，都涉及回忆过去的事件或行动。
- Procedural memory：程序性记忆，无论是在人类还是人工智能智能体中，都涉及记住执行任务所使用的规则。
