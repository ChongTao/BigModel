## 用户的query处理 

### 一 指代消解

用对话历史中提到的特定实体替换代词（it、this、that、they、he、she）

1. 基于规则（简单）
   - **指代词典** **+ 句法规则**：通过预定义的规则（如性别、数的一致性，句法结构约束）来确定代词的指向。例如："小王去见了小李，他很高兴" → 根据主谓一致规则，“他”更可能指小王。**优点**：实现简单，计算开销小。**缺点**：覆盖率有限，对复杂语境表现差。
2. 基于传统机器学习的方法
   - **特征工程** **+** **分类器**：将候选指代对转化为特征向量，训练模型判断是否为同一指代。特征包括：词性、句法距离、性别数一致性、上下文窗口词等。常用算法：SVM、逻辑回归、决策树。**代表性方法**：Mention-Pair Model、Entity-Mention Model。**缺点**：依赖人工特征，泛化能力差。
3. 基于神经网络的方法
   - **神经网络编码器（BiLSTM、CNN、Transformer）**：学习上下文表示，替代人工特征。**代表性模型**：
      - **End-to-End Coreference Resolution (Lee et al., 2017)**候选实体 span 表示 打分选择最可能的先行词。
      - **SpanBERT** 在 CoNLL 2012 上表现突出。**优点**：自动学习语义与上下文信息。**缺点**：需要大规模标注数据，计算开销大。
4. 基于大语言模型的方法
   - **上下文学习（In-Context Learning）**：直接用大模型理解代词，提供若干消解示例，让模型在 few-shot 下完成指代消解。
   - **指代消解作为下游任务**：将指代消解问题转化为“问答”或“文本填空”任务：
   - **检索增强（RAG）+ 消解**：将上下文实体存入向量数据库，遇到代词时检索可能指代对象，由模型完成最终判定。
   - **链式推理（Chain-of-Thought, CoT）**：要求模型先分析上下文逻辑链，再输出指代结果。

### 二 省略成分补全

添加根据上下文隐含的缺失主语、宾语或其他必要成分。

1. **基于规则/模板的方法**

   适合简单场景，构造规则库或模式匹配

   -  方法：定义常见的省略模式（如“主语省略”“时间省略”）。   利用上下文或默认值补全。

2. **基于上下文语境的补全**

   - 利用多轮对话上下文或历史query：**指代消解** + **query** **合成**：把“它”“这个”“明天”解析成上文明确的对象。把新输入与历史 query 进行拼接或重写，即多轮改写。

3. **基于大模型的语义补全**

   - 利用 **LLM** 做 query 补全，输入（上下文 + 当前 query），输出（完整的、无省略的 query）

   - **语义匹配**：通过 embedding 确认上下文中的核心主题。

   - **生成式改写**：模型自动生成完整表达。

4. **混合式方法**

   - 在实际工程里，常常结合：规则/模板处理常见省略（高频 query）。
   - LLM 处理复杂或长尾 query（灵活补全）。
   - 引入**检索增强（RAG）**，保证补全出来的 query 在语料库或知识库中真实存在。

### 三 上下文整合

结合先前对话轮次中的相关信息，使查询能够独立理解

1. **基于规则的上下文继承**
   
   - **最近一问继承**：如果用户的 query 省略主语，就继承上一个 query 的主题。
   
   - **会话窗口继承**：在多轮对话中，限定一个窗口（最近 N 轮），按顺序查找可补全的信息
2. **基于语义检索的上下文选择**
   
   - 将历史 query 和当前 query **向量化**，做相似度匹配。
   
   - 选出与当前 query 相关的上文，作为补全素材。
3. **大模型上下文整合**
   
   - 现在常用的 **LLM Query Rewriting** 方式：通过历史对话 + 当前 query 传递给大模型输出改写后的query核心技巧：
   
   - **上下文裁剪**：对历史对话做压缩，避免长对话超长。
   
   - **角色提示**：告诉模型“请用当前 query 补全成完整问句”。
4. **混合策略**
   1.   **规则优先**：处理高频场景（天气、时间、省略主语）。
   2.   **检索辅助**：用向量检索定位相关历史上下文。
   3.   **LLM 补全**：最后生成完整 query，保证自然性和灵活性。
   4.   **缓存机制**：避免重复调用模型，提升性能。

### 四 语义保留

保持用户查询的原始意图和含义  在query处理过程中容易丢失语义，常见原因包括：

- **过度补全**：系统为了完整，瞎加成分。

- **错继承**：上下文没选对。

 保留语义的常见方法：

- **最小改写原则**：只补全缺省信息，不改动原始用户输入；保留用户 query 中的词序和表达方式。

- **语义一致性检测**：用向量相似度/大模型判断补全前后是否“语义一致”。

- **多候选补全 + rerank**：先生成多个补全候选，用语义匹配模型rerank，选与原 query 语义最接近的。

- **引入约束Prompt**：在 LLM 重写时，加明确约束，不要添加用户未提及的实体或属性、保留用户query中的原词。

- **领域知识校验**：在特定领域，补全后的 query 可以用知识库校验：