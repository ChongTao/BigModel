

#  一 什么是 Prompt Engineering

Prompt Engineering（提示工程）是指**通过设计、组织和优化输入提示（prompt）**，使大语言模型在给定任务上生成**更准确、更稳定、更可控的输出**的一整套方法论。

> Prompt 就是模型的“指令”或“上下文”，Prompt Engineering 就是在“教模型该怎么想、怎么答”。



# 二 模型配置

**Temperature**：是大语言模型生成控制中最核心的超参数之一。 它直接影响模型输出的「创造性」、「确定性」和「多样性」。其值越小，模型返回的结果越确定，否则结果更加随机。在不同任务中配置不同，例如代码生成中建议配置0.0~0.2，而创作类讲义配置1.0。

**top_p**(nucleus sampling)：和 `temperature` 一样都控制 **输出的随机性与多样性**，如果你需要准确和事实的答案，就把参数值调低。如果你在寻找更多样化的响应，可以将其值调高点。

**max_tokens**：模型一次生成的最大 token 数。

**presence_penalty**：惩罚已出现过的 token，鼓励话题多样化

**frequency_penalty**：惩罚重复出现的 token，减少重复句。

**stop**：指定模型遇到哪些 token/字符串时停止输出



# 三 提示词工程

[提示词工程简介](https://www.promptingguide.ai/zh/introduction)

- **零样本提示**：在没有提供任何示例（样本）的情况下，仅依靠任务指令（instruction）让模型直接完成任务的一种提示方式。
- **Few-Shot Prompting**： 是指在提示（prompt）中给模型提供 **几个示例（通常2–5个）**，让模型学习这些示例的**任务格式、风格和逻辑**，然后再对新输入进行输出。
- **CoT**：通过让模型 **“展示推理过程”**，而不仅仅直接给出答案，来显著提升模型在**复杂推理、数学计算、逻辑判断**等任务上的表现。
- 自我一致性：基于 **Chain-of-Thought（CoT）** 的推理增强方法。**让模型生成多个不同的思维链推理路径，然后选出最一致（出现最多）的最终答案。**
- 生成知识提示：让大模型在回答问题前，**主动生成或回忆相关知识**的提示方法。
- **链式提示（Chain Prompting）**： 是一种将复杂任务拆分为多个连续子任务、 并通过多轮提示让模型逐步完成整个任务的提示策略。
- **思维树**：模型不止生成一条推理链，而是像树一样生成多个“思考分支（Thoughts）”，并在不同分支中进行探索、比较和选择，从而提高推理的正确率。
- **RAG**： 一种结合了 **信息检索（Retrieval）** 与 **文本生成（Generation）** 的混合式架构，用于让大语言模型（LLM）在生成内容时能够 **访问外部知识**。
- **自动推理并使用工具（Reasoning + Tool Use）**： 是指模型在生成过程中，能够**动态决定何时、如何调用外部工具（API、数据库、计算函数等）**来完成任务，而不是单纯依赖内部知识生成答案。
- **Active-Prompt**（主动提示）：基于 **主动学习（Active Learning）思想** 的提示优化方法。它让大语言模型（LLM）能够在不同任务中自动探索、生成、筛选和更新最优的提示（Prompt）。传统 Prompt Engineering 是 **人工设计提示词**，而 Active-Prompt 让模型 **自己学会设计和改进提示词**。
- **ReAct**：Reasoning + Acting，让大语言模型在解决复杂任务时，**边推理边行动**的框架。
- **自我反思（Self-Reflection）** ：指模型在生成答案或执行任务后，**回顾自己的推理过程、评估结果正确性，并尝试发现或纠正错误**的机制。



# 四 模型应用概念

- **Function Calling** ：是指让模型在生成文本的同时，**生成结构化调用指令（函数或 API 调用）**，而不是仅仅输出自然语言答案。
- **Context-Caching**：指的是在多轮对话或任务执行中，**将模型生成的上下文、推理状态或检索结果缓存下来**，以便后续请求直接复用，减少重复计算，提高响应速度和一致性。