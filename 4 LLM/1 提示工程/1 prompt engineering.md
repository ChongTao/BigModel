#  一  Prompt Engineering

Prompt Engineering（[提示词工程简介](https://www.promptingguide.ai/zh/introduction)）指的是**通过合理设计提示（Prompt）来引导大语言模型（LLM）产生期望输出**的系统性方法论。

其核心目标是：

- 提高模型回答的**准确性、稳定性、可控性**
- 减少模型的**幻觉**
- 提高模型的**推理、规划、执行能力**

## 1.1 核心原则

- 角色：角色定位清晰，告诉模型你是谁（你是一个语音助手）
- 指令：告诉模型要做什么、目标是什么，有没有什么限制
- 上下文：包含外部信息，用于引导模型更好响应
- 输出：输出格式明确，告诉模型以什么格式输出
- 示例：给模型示例，模型将遵循示例



## 1.2 提示技术

- **零样本提示**：在没有提供任何示例（样本）的情况下，仅依靠任务指令（instruction）让模型直接完成任务的一种提示方式。
- **Few-Shot Prompting**： 是指在提示（prompt）中给模型提供 **几个示例（通常2–5个）**，让模型学习这些示例的**任务格式、风格和逻辑**，然后再对新输入进行输出。
- **CoT**：通过让模型 **“展示推理过程”**，而不仅仅直接给出答案，来显著提升模型在**复杂推理、数学计算、逻辑判断**等任务上的表现。
- **自我一致性**：基于 **Chain-of-Thought（CoT）** 的推理增强方法。**让模型生成多个不同的思维链推理路径，然后选出最一致（出现最多）的最终答案。**
- 生成知识提示：让大模型在回答问题前，**主动生成或回忆相关知识**的提示方法。
- **链式提示（Chain Prompting）**： 是一种将复杂任务拆分为多个连续子任务、 并通过多轮提示让模型逐步完成整个任务的提示策略([Prompt Chaining](https://github.com/ginobefun/agentic-design-patterns-cn/blob/main/07-Chapter-01-Prompt-Chaining.md))。
- **思维树**：模型不止生成一条推理链，而是像树一样生成多个“思考分支（Thoughts）”，并在不同分支中进行探索、比较和选择，从而提高推理的正确率。
- **RAG**： 一种结合了 **信息检索（Retrieval）** 与 **文本生成（Generation）** 的混合式架构，用于让大语言模型（LLM）在生成内容时能够 **访问外部知识**。
- **自动推理并使用工具（Reasoning + Tool Use）**： 是指模型在生成过程中，能够**动态决定何时、如何调用外部工具（API、数据库、计算函数等）**来完成任务，而不是单纯依赖内部知识生成答案。
- **Active-Prompt**（主动提示）：基于 **主动学习（Active Learning）思想** 的提示优化方法。它让大语言模型（LLM）能够在不同任务中自动探索、生成、筛选和更新最优的提示（Prompt）。传统 Prompt Engineering 是 **人工设计提示词**，而 Active-Prompt 让模型 **自己学会设计和改进提示词**。
- **ReAct**：Reasoning + Acting，让大语言模型在解决复杂任务时，**边推理边行动**的框架。
- **自我反思（Self-Reflection）** ：指模型在生成答案或执行任务后，**回顾自己的推理过程、评估结果正确性，并尝试发现或纠正错误**的机制。
