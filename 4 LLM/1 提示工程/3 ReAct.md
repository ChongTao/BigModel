# 1 ReAct介绍

[ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/pdf/2210.03629)提出ReAct范式，通过构建“推理-行动-观察”（TAO）的机制，实现了语言模型推理能力与外部环境交互能力的深度协同(https://mp.weixin.qq.com/s/YQfqLoL1Z94yx9z48CE8bQ)。该框架的核心灵感来源于人类决策过程：我们不只是被动思考，而是通过思考制定计划、执行行动、观察结果，并据此调整策略。ReAct将这一过程应用到LLM中，使模型能够动态处理复杂任务。

ReAct之前大模型常见问题：

- **链式思考（CoT）：**无法与外部世界互动，容易导致事实幻觉（Fact Hallucination）和错误传播。
- **仅行动（Act-Only）：**缺乏规划能力，在多步骤任务中表现不佳。

ReAct是通过推理-行动-思考的过程来解决之前的问题，其中

- **推理（Reasoning）：**模型生成内部思考轨迹，例如"我需要先做什么，再做什么"，类似于链式思考（Chain-of-Thought, CoT）。这有助于分解任务、制定计划和处理异常。
- **行动（Acting）：**模型生成可执行的操作，例如"搜索[关键词]"或"计算[表达式]"，以调用外部工具（如搜索引擎或计算器）获取实时信息。

![](https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd02b2eaa-16c3-4f92-8f97-06329fbcccd4_716x550.gif)



与之前的技术相比，ReAct具有三个核心特征：

- **显式推理过程**：大模型在执行任务前会生成思考过程，清晰说明任务的轨距，解决之前直接给出答案，而不清楚为什么是这个答案。

- **外部资源**：通过调用外部工具（天气查询、航班查询等）获取最新、更专业的数据 ，减少模型幻觉

- **少量样本泛化**：仅需要1-5个包含”推理-行动-观察“的few-shot，即可快速适配多场景任务，无需微调

# 2 ReAct核心思想 

ReAct的核心思想源于人类解决复杂问题的认知过程：让模型在解决复杂问题时，像人一样在**“思考（推理）->行动（与外部世界交互）-> 再思考”**之间循环，把“脑内推理”与“外部证据”动态绑定，从而减少纯靠臆测的长链推理，提升可控性与可解释性。ReAct将这一过程抽象为“Thought（推理）→Act（行动）→Observe（观察）”的TAO闭环。

- **Thought（推理）**：我现在知道什么？缺什么？下一步该做什么？
- **Action（行动）**：去调用工具/检索/执行操作来获取信息或推进状态
- **Observation（观察）**：工具返回了什么？这改变了什么判断？

## 2.1 ReAct核心认知原则 

1. 不确定就别硬推，先做“信息增益最大”的动作
   - 人类做题也一样：卡住时不是继续脑补，而是“查一下/验证一下”。
   - ReAct把这件事变成机制：推理负责找“信息缺口”，行动负责补上。

2. 推理是用来选择行动的，不是用来生成答案的
   - 在复杂任务中，“答案”往往是行动序列的结果
   - ReAct把推理从“直接产出最终结论”转成“决策引擎”。
3. 每一步都要被外部证据校正
   - 纯推理容易越想越偏（幻觉、偏航、遗漏约束），ReAct用 Observation 把推理拉回现实：**证据驱动收敛**。

# 3 ReAct工作原理

ReAct 通过 **推理 → 行动 → 观察 → 再推理的闭环**，把不确定性逐步转化为确定性，用外部反馈约束模型的推理路径。

![](https://www.dailydoseofds.com/content/images/2025/04/image-33.png)

## 3.1 推理（Thought）

模型基于“任务目标+历史TAO轨迹”生成推理内容，核心输出有三个关键信息：一是评估当前已知的信息（已获取哪些信息、缺少哪些信息）；二是找到关键未知点；三是决定“下一步最值得做的事”（包括调用什么工具、预期是什么）。它不是“解题推导”，而是 **决策推理**，其推理轨迹的质量直接决定行为有效性，通常通过提示词工程强制连贯性。

## 3.2 行动（Act）

把抽象推理落到**具体可执行操作**，包括工具类型和参数（注意该类工具定义要明确性能够指导后续模型执行，如`Action: WebSearch("population of Canada 2023")`），常见的Action如下， Action 是**有成本的**，ReAct 的推理要学会“少而准”。

- Search / Retrieve
- Call API / Tool
- Run Code
- Ask Clarifying Question
- Write / Modify State

## 3.3 观察（Observe）

接收 Action 的结果，并将结果以“结构化、去冗余”的形式返回注入下一次推理

## 3.4 闭环收敛

ReAct 能工作的关键在于 **闭环而不是长链**。当满足以下任一终止条件时，循环停止并输出结果：

1. **正常终止：**模型输出finish行动，表明已完成任务目标；
2. **超时终止：**达到预设最大迭代步数（通常5-10步，依任务复杂度调整）；
3. **异常终止：**连续3次行动失败（如工具调用超时、参数错误），触发熔断机制。

> 注意每一轮循环都应该：消除一个未知或验证/否定一个假设，如果本轮没有获取新信息或者状态没有改变，则本轮是无效行动，需要被惩罚或截断

# 4 技术架构

ReAct是一个有状态的推理控制回路

```sql
┌─────────────────────────────┐
│        Goal / Task           │
└─────────────┬───────────────┘
              ↓
┌─────────────────────────────┐
│     Reasoning Layer          │  ← Thought
│  (LLM + Prompt + Policy)     │
└─────────────┬───────────────┘
              ↓
┌─────────────────────────────┐
│      Action Planner          │  ← Action
│  (Tool Selection / Params)  │
└─────────────┬───────────────┘
              ↓
┌─────────────────────────────┐
│     Tool / Environment       │
│  (Search / API / Code)      │
└─────────────┬───────────────┘
              ↓
┌─────────────────────────────┐
│     Observation Handler      │  ← Observation
│  (Parse / Validate / Store) │
└─────────────┬───────────────┘
              ↓
┌─────────────────────────────┐
│     State / Memory           │
│  (Short-term / Long-term)   │
└─────────────┴───────────────┘
              ↑
        Control Loop
```

## 4.1 推理层 / LLM Brain

负责推理轨迹生成与行动规划，主要由“LLM+提示工程模块”构成，核心功能包括：

- **推理引擎：**基于任务目标与历史上下文，生成逻辑连贯的推理轨迹，明确行动依据。核心依赖LLM的上下文理解与逻辑推理能力，如GPT-5、Claude 3等；
- **行动规划器：**将推理结果转化为标准化行动指令，确保格式合规、参数完整。通过提示工程中的格式约束（如“行动必须为XX格式”）实现；
- **提示优化模块：**通过调整温度参数（0.2-0.3，降低随机性）、加入负面示例（如“避免重复调用同一工具”）等方式，优化LLM输出质量。

## 4.2 行动规划层

负责把“抽象行动意图”转成**可执行指令**，选择合适的工具并生成对应参数

## 4.3 工具与环境层

负责执行Action与外部进行交互。

## 4.4 观察处理层

控制迭代节奏，执行终止判断条件。每轮迭代后检查是否满足终止条件，若满足则触发结果输出，否则驱动流程返回核心逻辑层进入下一轮推理。



# 5 解决问题

ReAct范式的核心价值在于针对性解决了传统AI技术在复杂任务中面临的关键痛点，显著提升了智能系统的实用性。

## 5.1 纯推理易幻觉

传统LLM的推理完全依赖预训练阶段习得的内部知识，当面临实时信息、专业领域知识时，模型生成与事实不符的“幻觉内容”。

长链CoT一旦前面错误，后面**全错且自洽**，ReAct通过"思考（推理）->行动（与外部世界交互）-> 再思考"的链路，推理过程定位到真实数据。

## 5.2  复杂任务不可控

传统模式下一次性生成完整方案，一旦执行失败时才能发现错误，需要大量训练。ReAct依托LLM的推理能力，可通过少量示例快速生成动态策略。



## 5.3  推理过程不可解释、不可调试

传统深度学习模型的决策过程是“黑箱”，无法解释“为什么做出该决策”，一旦出错将无法定位，ReAct通过显式 "思考->行动-> 观察"轨迹，每一步行动均有明确的逻辑依据，可用于推理路径可追溯，方便定位。



# 6 应用场景

ReAct框架在多个领域都有广泛的应用场景，以下是一些典型的使用场景和实践示例：

## 6.1 知识密集型问答

在需要准确事实信息的任务中，ReAct能够通过外部工具获取最新信息，避免模型幻觉。

```text
# 知识密集型问答示例
agent.run("2024年诺贝尔物理学奖得主是谁？他们的主要贡献是什么？")
```

## 6.2 复杂决策任务

在需要多步骤规划和决策的任务中，ReAct能够制定策略并动态调整。

```text
# 旅行规划示例
agent.run("为一个三口之家规划一个周末从北京到天津的亲子旅行，预算3000元")
```

## 6.3 数据分析与计算

结合计算器等工具，ReAct能够执行复杂的数值计算和数据分析任务。

```text
# 数据分析示例
agent.run("计算2023年公司各季度销售额增长率，并预测2024年第一季度销售额")
```

## 6.4 编程辅助

在编程任务中，ReAct能够通过搜索文档、执行代码片段来辅助开发，以爱码仕ai编程工具使用为例，ReAct框架被用于智能代码生成、错误诊断与修复、技术选型建议等场景。

```text
# 爱码仕中的ReAct应用示例
agent.run("创建一个React组件，实现用户登录表单，包含邮箱和密码验证功能")
在LangChain框架中，实现ReAct代理很简单：
```

- 初始化LLM和工具（如Web搜索）。
- 使用initialize_agent创建代理。



# 7 ReAct优势对比

| 对比维度     | ReAct                        | 传统思维链（CoT）        | Toolformer                 | 强化学习（RL）             |
| :----------- | :--------------------------- | :----------------------- | :------------------------- | :------------------------- |
| 核心能力     | 推理与行动协同，自主决策     | 纯推理，无外部交互能力   | 工具调用，推理逻辑薄弱     | 行动优化，无显式推理       |
| 幻觉抑制能力 | 强（行动锚定外部事实）       | 弱（依赖内部知识）       | 中（工具调用但推理不足）   | 中（环境反馈但无事实校验） |
| 可解释性     | 强（显式推理轨迹+行动依据）  | 中（仅推理链无行动关联） | 弱（仅工具调用记录）       | 弱（黑箱式策略）           |
| 场景适配性   | 强（模块化替换工具集）       | 弱（仅适用于纯推理任务） | 中（仅适用于工具相关任务） | 弱（单场景定制训练）       |
| 落地成本     | 低（Few-shot适配，无需微调） | 低（无需工具）           | 中（需工具适配与微调）     | 高（大规模数据训练）       |

通过对比可见，ReAct在推理与行动的协同能力、幻觉抑制效果、场景适配性上均展现出显著优势，尤其适用于需要“主动决策+动态反馈”的复杂现实场景。

