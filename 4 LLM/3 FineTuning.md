# 一 定义

**Fine-tuning（微调）** 是指在已经训练好的大语言模型基础上，使用 **特定任务或特定领域的数据** 对模型进行二次训练，从而让模型在目标任务上表现更好。

------

# 二 目标

1. **任务适配**
   - 让模型在特定任务（分类、生成、问答等）上更准确。
2. **领域知识注入**
   - 将专业领域的数据（医疗、法律、金融等）融入模型，使其输出符合行业要求。
3. **行为规范化**
   - 微调模型输出风格、礼貌性、逻辑性等，提高用户体验。

------

# 三、微调方法

## 3.1 全参数微调（Full Fine-tuning）

- 对模型所有参数进行更新。
- 优点：适配性强，任务表现最佳。
- 缺点：计算成本高，需要大量数据和 GPU 资源。

## 3.2 LoRA（Low-Rank Adaptation）

- 只微调模型的低秩权重矩阵。
- 优点：参数少、训练快、存储小。
- 缺点：任务适应性略低于全参数微调。

## 3.3 Prefix-Tuning / P-Tuning

- 在输入中添加可学习的“前缀向量”，微调前缀参数。
- 优点：训练参数少，灵活性高。
- 缺点：可能对复杂任务适配不足。

## 3.4 Adapter 微调

- 在模型中插入小型适配层，只训练这些层。
- 优点：参数量小，可多任务共存。
- 缺点：复杂任务可能需要更多设计。

------

#  四 Fine-tuning 流程

1. **数据准备**
   - 收集高质量任务数据（问答对、文本分类标签、指令等）
   - 数据清洗与格式化
2. **选择微调策略**
   - 全参数微调 / LoRA / Prefix / Adapter
3. **训练微调**
   - 将数据输入预训练模型进行梯度更新
   - 可采用监督学习、RLHF 等方法
4. **验证与评估**
   - 使用验证集评估任务效果
   - 调整学习率、训练轮次等参数
5. **部署与推理**
   - 将微调后的模型用于生产环境

------

# 五 应用场景

| 场景       | 说明                                             |
| ---------- | ------------------------------------------------ |
| 指令调优   | 微调模型更好地执行指令式任务（InstructGPT 思路） |
| 领域适配   | 医疗问答、金融分析、法律文本生成等               |
| 风格定制   | 调整模型生成风格（幽默、正式、简洁等）           |
| 多任务共享 | 使用 Adapter / LoRA 支持同一模型多任务微调       |
